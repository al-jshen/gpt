{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e00718f-0ca6-4e42-816c-7bc322aa9eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ceacbe4-4305-494a-956a-29c966820f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from gpt.data import ImagenetH5DataModule\n",
    "from gpt.model import ViT, ClassificationHead, LightningWrapper\n",
    "from torch.nn import functional as F\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c9e4e02-a3ec-42db-8a6e-3b1358d3c8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/gpfs/js5013/.conda/envs/foundation/lib/python3.11/site-packages/lightning/pytorch/utilities/parsing.py:198: Attribute 'output_head' is an instance of `nn.Module` and is already saved during checkpointing. It is recommended to ignore them using `self.save_hyperparameters(ignore=['output_head'])`.\n"
     ]
    }
   ],
   "source": [
    "v = LightningWrapper(ViT, image_size=(224, 224), patch_size=(16, 16), image_channels=3, embed_dim=384, mlp_ratio=4, num_heads=8, num_blocks=6, dropout=0.1, lr=1e-3, output_head=ClassificationHead(384, 1000), loss_fn=F.cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87009398-5233-4eca-8bfc-ed2d8caa6f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate(lop):\n",
    "    x, y = zip(*lop)\n",
    "    x = torch.stack(x)\n",
    "    return x.view(-1, *x.shape[2:]), torch.tensor(y).unsqueeze(-1).repeat(1, x.shape[1]).view(-1)\n",
    "    \n",
    "imagenet = ImagenetH5DataModule(crop_transform=lambda x: x, extra_transforms=[transforms.FiveCrop(224), transforms.Lambda(torch.stack)], batch_size=16, collate_fn=collate)\n",
    "imagenet.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02a6259a-0744-4d27-9ba1-11891a9085b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl = imagenet.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "442ceaed-abf8-4c27-8ba0-34ed9e67db76",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(tl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e5d027ab-3b8b-4032-b203-7484ff67906e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7.0102, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v.loss_fn(v(x), y.long())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c440f5c5-6a24-49c6-aa66-0249da96bdb2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
